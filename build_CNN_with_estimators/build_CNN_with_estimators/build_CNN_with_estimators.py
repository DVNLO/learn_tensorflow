# The following is an exploration of a tensor flow tutorial to "Build a
# Convolutional Neural Network using Estimators".  The tutorial can be found
# at the following address: https://www.tensorflow.org/tutorials/estimators/cnn

#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
"""Convolutional Neural Network Estimator for MNIST, built with tf.layers."""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)


def cnn_model_fn(features, labels, mode):
  """Model function for CNN."""
  # Input Layer
  # Reshape X to 4-D tensor: [batch_size, width, height, channels]
  # MNIST images are 28x28 pixels, and have one color channel
  input_layer = tf.reshape(features["x"], [-1, 28, 28, 1])

  # Convolutional Layer #1
  # Computes 32 features using a 5x5 filter with ReLU activation.
  # Padding is added to preserve width and height.
  # Input Tensor Shape: [batch_size, 28, 28, 1]
  # Output Tensor Shape: [batch_size, 28, 28, 32]
  conv1 = tf.layers.conv2d(
      inputs=input_layer,
      filters=32,
      kernel_size=[5, 5],
      padding="same",
      activation=tf.nn.relu)

  # Pooling Layer #1
  # First max pooling layer with a 2x2 filter and stride of 2
  # Input Tensor Shape: [batch_size, 28, 28, 32]
  # Output Tensor Shape: [batch_size, 14, 14, 32]
  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

  # Convolutional Layer #2
  # Computes 64 features using a 5x5 filter.
  # Padding is added to preserve width and height.
  # Input Tensor Shape: [batch_size, 14, 14, 32]
  # Output Tensor Shape: [batch_size, 14, 14, 64]
  conv2 = tf.layers.conv2d(
      inputs=pool1,
      filters=64,
      kernel_size=[5, 5],
      padding="same",
      activation=tf.nn.relu)

  # Pooling Layer #2
  # Second max pooling layer with a 2x2 filter and stride of 2
  # Input Tensor Shape: [batch_size, 14, 14, 64]
  # Output Tensor Shape: [batch_size, 7, 7, 64]
  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

  # Flatten tensor into a batch of vectors
  # Input Tensor Shape: [batch_size, 7, 7, 64]
  # Output Tensor Shape: [batch_size, 7 * 7 * 64]
  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])

  # Dense Layer
  # Densely connected layer with 1024 neurons
  # Input Tensor Shape: [batch_size, 7 * 7 * 64]
  # Output Tensor Shape: [batch_size, 1024]
  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)

  # Add dropout operation; 0.6 probability that element will be kept
  dropout = tf.layers.dropout(
      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

  # Logits layer
  # Input Tensor Shape: [batch_size, 1024]
  # Output Tensor Shape: [batch_size, 10]
  logits = tf.layers.dense(inputs=dropout, units=10)

  predictions = {
      # Generate predictions (for PREDICT and EVAL mode)
      "classes": tf.argmax(input=logits, axis=1),
      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the
      # `logging_hook`.
      "probabilities": tf.nn.softmax(logits, name="softmax_tensor")
  }
  if mode == tf.estimator.ModeKeys.PREDICT:
    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

  # Calculate Loss (for both TRAIN and EVAL modes)
  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)

  # Configure the Training Op (for TRAIN mode)
  if mode == tf.estimator.ModeKeys.TRAIN:
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
    train_op = optimizer.minimize(
        loss=loss,
        global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

  # Add evaluation metrics (for EVAL mode)
  eval_metric_ops = {
      "accuracy": tf.metrics.accuracy(
          labels=labels, predictions=predictions["classes"])}
  return tf.estimator.EstimatorSpec(
      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)


##############################################################################

def main(unused_argv):
  # Load training and eval data
  mnist = tf.contrib.learn.datasets.load_dataset("mnist")
  train_data = mnist.train.images  # Returns np.array
  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)
  eval_data = mnist.test.images  # Returns np.array
  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)

  # Create the Estimator
  mnist_classifier = tf.estimator.Estimator(
      model_fn=cnn_model_fn, model_dir="/tmp/mnist_convnet_model")

  # Set up logging for predictions
  # Log the values in the "Softmax" tensor with label "probabilities"
  tensors_to_log = {"probabilities": "softmax_tensor"}
  logging_hook = tf.train.LoggingTensorHook(
      tensors=tensors_to_log, every_n_iter=50)

  # Train the model
  train_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={"x": train_data},
      y=train_labels,
      batch_size=100,
      num_epochs=None,
      shuffle=True)
  mnist_classifier.train(
      input_fn=train_input_fn,
      steps=20000,
      hooks=[logging_hook])

  # Evaluate the model and print results
  eval_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={"x": eval_data},
      y=eval_labels,
      num_epochs=1,
      shuffle=False)
  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)
  print(eval_results)

if __name__ == "__main__":
    tf.app.run()

"""
EXAMPLE OUTPUT::

INFO:tensorflow:global_step/sec: 5.53906
INFO:tensorflow:probabilities = [[0.00001743 0.00025173 0.9591319  0.00820096 0.00020747 0.00002829
  0.00094485 0.03115867 0.00005324 0.00000542]
 [0.         0.         0.         0.00000272 0.         0.9999434
  0.00000001 0.         0.00005383 0.00000002]
 [0.00000001 0.         0.00000576 0.00001682 0.00000001 0.00000001
  0.         0.9999703  0.00000001 0.00000698]
 [0.00000905 0.00516407 0.00003854 0.00570529 0.05497485 0.00163765
  0.00000117 0.02361589 0.00035603 0.9084975 ]
 [0.00003372 0.00017863 0.00002458 0.99747926 0.00000004 0.00217183
  0.00000002 0.00000097 0.000001   0.00011   ]
 [0.9996506  0.00000003 0.00000717 0.00004306 0.00000003 0.00026375
  0.00003316 0.00000024 0.00000163 0.0000005 ]
 [0.90882015 0.00010453 0.00731953 0.04718952 0.00002098 0.00047886
  0.00010599 0.00172181 0.03215327 0.00208524]
 [0.00005502 0.0000006  0.00008231 0.00003047 0.9938332  0.00049089
  0.0001365  0.0003415  0.00011648 0.00491314]
 [0.9995291  0.         0.00005508 0.00000158 0.00000079 0.00000224
  0.00018889 0.00017385 0.00000062 0.00004795]
 [0.00000273 0.9995415  0.00005345 0.00017117 0.00001141 0.00002655
  0.00000245 0.00011586 0.00007111 0.00000353]
 [0.00000047 0.00000101 0.00049946 0.00053548 0.00000395 0.00002954
  0.00000055 0.00000201 0.99763286 0.00129464]
 [0.00028508 0.00000024 0.00000204 0.00055511 0.00008088 0.99559563
  0.00006329 0.00000089 0.00085147 0.00256531]
 [0.00000005 0.00001118 0.00008671 0.00016884 0.00000858 0.0000189
  0.00029197 0.00000023 0.99940133 0.00001218]
 [0.00004596 0.00000211 0.00156567 0.00001375 0.00661005 0.00013931
  0.991597   0.00000014 0.00001451 0.00001148]
 [0.00000004 0.00000001 0.00000107 0.00005554 0.00000596 0.00000066
  0.         0.99832827 0.00000118 0.00160722]
 [0.00004655 0.9792119  0.00012088 0.00031933 0.00020922 0.00224334
  0.00131055 0.0000022  0.01587561 0.00066039]
 [0.00000134 0.00004668 0.00218752 0.00637693 0.00000651 0.00000217
  0.         0.99104226 0.00000617 0.00033039]
 [0.00000634 0.99853075 0.00005702 0.00013371 0.00005548 0.00001322
  0.00005108 0.00084328 0.0002979  0.00001126]
 [0.00000813 0.00001352 0.00075002 0.00013396 0.00004039 0.0006004
  0.00016469 0.00000023 0.9978447  0.00044395]
 [0.00001541 0.98893857 0.00005396 0.00022245 0.00000523 0.00012868
  0.0000033  0.00099036 0.00676024 0.00288181]
 [0.00001841 0.00001041 0.00032895 0.00547894 0.00363064 0.00009032
  0.00000258 0.00996082 0.00121091 0.9792681 ]
 [0.00001762 0.00000002 0.00000835 0.0000001  0.9992508  0.00000603
  0.00047614 0.00000227 0.00001307 0.00022552]
 [0.00000284 0.00000011 0.00003634 0.00000118 0.00004083 0.00006648
  0.9997342  0.         0.0001176  0.0000003 ]
 [0.0000001  0.00006998 0.00002514 0.9995129  0.00000005 0.00003842
  0.         0.00000175 0.00031445 0.00003734]
 [0.99934393 0.         0.00003508 0.00000219 0.00000021 0.00012061
  0.00000101 0.00000771 0.00038333 0.000106  ]
 [0.99999905 0.         0.00000009 0.         0.         0.00000029
  0.         0.00000056 0.00000001 0.00000002]
 [0.32645535 0.00033754 0.17007063 0.02610587 0.01028968 0.05536265
  0.12576976 0.00167584 0.2768447  0.00708797]
 [0.00000001 0.         0.00000001 0.00000002 0.99999523 0.00000096
  0.00000017 0.00000012 0.00000023 0.00000335]
 [0.00002521 0.00001479 0.00000856 0.9625024  0.00009555 0.00038342
  0.00000045 0.00013855 0.00013515 0.03669578]
 [0.00011611 0.00000091 0.00029081 0.00216262 0.00140756 0.00007991
  0.00000076 0.03082246 0.00021701 0.96490186]
 [0.00000001 0.         0.0000021  0.0000011  0.99985087 0.00000007
  0.00000089 0.00003807 0.00000066 0.00010626]
 [0.00064659 0.00000034 0.00020119 0.00000122 0.001407   0.0000752
  0.9976095  0.00000037 0.00003947 0.00001918]
 [0.00004074 0.9891452  0.00101289 0.00080914 0.00005209 0.00594475
  0.00063051 0.00000309 0.00219075 0.00017102]
 [0.00001495 0.00001717 0.00005773 0.00221132 0.00018911 0.981037
  0.00016352 0.00001165 0.00532743 0.01097007]
 [0.00000147 0.         0.00000073 0.00022507 0.00004066 0.00001629
  0.         0.99491984 0.0000121  0.00478387]
 [0.00002711 0.0000141  0.00655662 0.00314194 0.00000086 0.08500261
  0.00000258 0.00012525 0.9045927  0.00053623]
 [0.00147657 0.00001155 0.98549545 0.00026559 0.00004082 0.00001128
  0.00005969 0.00003511 0.01081199 0.00179201]
 [0.0000836  0.00057733 0.00018987 0.96952933 0.00005612 0.02727005
  0.00004134 0.0001644  0.00058636 0.00150166]
 [0.00000158 0.00037989 0.00033482 0.9968079  0.00000036 0.00065016
  0.00000005 0.00001674 0.00137774 0.00043089]
 [0.0000011  0.0000033  0.00002593 0.00035911 0.9775965  0.00001023
  0.00000395 0.0010437  0.00058028 0.0203758 ]
 [0.00123716 0.00000011 0.9634774  0.0018821  0.0037619  0.00020576
  0.02843929 0.00000207 0.00049357 0.00050092]
 [0.00000075 0.         0.00000079 0.00075195 0.00000937 0.00101636
  0.00000057 0.0000116  0.9966455  0.00156309]
 [0.00002756 0.00000239 0.10737749 0.0003512  0.01721513 0.00047962
  0.8740079  0.00017321 0.0003263  0.00003931]
 [0.00034548 0.00000108 0.00001112 0.00512926 0.00084592 0.98813194
  0.00120696 0.00000651 0.0006807  0.00364101]
 [0.00035646 0.00235981 0.0000863  0.00022704 0.00009719 0.00070728
  0.00110772 0.00000171 0.99503005 0.00002644]
 [0.9956987  0.00000011 0.0013109  0.00003858 0.00001434 0.00005862
  0.00263919 0.00000148 0.00020573 0.00003242]
 [0.00078063 0.00000282 0.00419076 0.00102293 0.00000773 0.00000293
  0.00002895 0.0000001  0.9939255  0.00003763]
 [0.9998074  0.00000001 0.00002599 0.00000155 0.0000003  0.00005772
  0.00000197 0.00000042 0.00001258 0.00009198]
 [0.00007664 0.00000052 0.00016478 0.00008393 0.00015902 0.00000321
  0.00001374 0.00002234 0.99892837 0.00054739]
 [0.00000867 0.00001533 0.0001395  0.9979851  0.00000167 0.00073653
  0.00000025 0.00000214 0.00075955 0.00035131]
 [0.00030491 0.00000446 0.00283215 0.98258096 0.00000318 0.00328017
  0.00000058 0.00002485 0.01065485 0.00031391]
 [0.00000014 0.00000004 0.00000551 0.0002545  0.9919161  0.00010933
  0.00001384 0.00170648 0.00006843 0.00592541]
 [0.00326718 0.00653654 0.00165124 0.01345764 0.00104828 0.09381816
  0.00738143 0.00029421 0.844998   0.02754727]
 [0.00000262 0.00028014 0.9871634  0.00300456 0.00112792 0.00015671
  0.00002962 0.00810244 0.00000797 0.00012433]
 [0.9993513  0.         0.00001494 0.00000002 0.00000083 0.00000125
  0.00062114 0.00000001 0.00001015 0.00000045]
 [0.00009807 0.9440691  0.00467515 0.00374943 0.00413666 0.00641158
  0.00447348 0.0004008  0.03069097 0.00129481]
 [0.00017282 0.00002709 0.00008706 0.00020065 0.00078732 0.0020839
  0.99485886 0.00000009 0.00177737 0.00000479]
 [0.00001021 0.00003729 0.990328   0.00397502 0.00014924 0.00019248
  0.00013659 0.00000139 0.00459831 0.00057146]
 [0.23911725 0.00015748 0.24240305 0.00192308 0.5004874  0.00166103
  0.00470083 0.00528471 0.00078837 0.0034769 ]
 [0.00001416 0.         0.00000255 0.00002227 0.00002268 0.00000396
  0.00000006 0.9973876  0.00000017 0.00254654]
 [0.00059613 0.01351845 0.93063676 0.02836889 0.00014044 0.00018504
  0.00528834 0.0000215  0.02123444 0.00000992]
 [0.00000194 0.         0.00001005 0.00000016 0.00000183 0.00000157
  0.9999727  0.         0.00001186 0.        ]
 [0.00722851 0.01526725 0.43565944 0.53661335 0.000001   0.00006741
  0.00000368 0.00106217 0.00325301 0.00084417]
 [0.00000036 0.0000674  0.00041761 0.00037681 0.9802423  0.00182406
  0.00046407 0.00000784 0.00130148 0.01529808]
 [0.00000001 0.         0.00000001 0.00000141 0.00000006 0.00000029
  0.         0.999686   0.00000119 0.00031108]
 [0.00187015 0.00001764 0.00090042 0.0000522  0.00193849 0.00024995
  0.9947358  0.00000837 0.00017743 0.00004954]
 [0.00000011 0.0000001  0.00000432 0.00032096 0.00000003 0.00000011
  0.         0.9994941  0.00000291 0.00017744]
 [0.00000141 0.9990044  0.00000533 0.00000706 0.0000057  0.00000118
  0.00000254 0.00000254 0.00096355 0.00000631]
 [0.00000001 0.0000108  0.99991035 0.00007405 0.         0.00000002
  0.         0.         0.00000482 0.        ]
 [0.00001307 0.00000195 0.00148911 0.00000377 0.00889535 0.00002313
  0.98950535 0.00000071 0.00005413 0.0000134 ]
 [0.00000046 0.00000009 0.00000045 0.000066   0.00000217 0.00000359
  0.         0.99763095 0.00000234 0.00229383]
 [0.00000207 0.0000001  0.0000121  0.0000413  0.9891594  0.00012888
  0.00001004 0.0003083  0.00077547 0.00956238]
 [0.9511551  0.00000024 0.00074013 0.00295273 0.0000325  0.00259279
  0.00002643 0.00419943 0.00036673 0.037934  ]
 [0.00019282 0.00000761 0.00009443 0.09269205 0.00001233 0.8905042
  0.00000984 0.00667731 0.0050138  0.0047956 ]
 [0.02040602 0.00008765 0.968708   0.00675923 0.00000586 0.00206858
  0.00000178 0.0001232  0.00132978 0.0005099 ]
 [0.00000003 0.00003059 0.99963593 0.00033278 0.         0.
  0.         0.00000004 0.0000006  0.        ]
 [0.00000013 0.00000069 0.00011947 0.00001512 0.9989298  0.00017804
  0.00033047 0.00010938 0.00005705 0.00025981]
 [0.00000201 0.00000029 0.00007547 0.00003089 0.00005725 0.00001797
  0.00000067 0.0000007  0.99963534 0.00017937]
 [0.0000008  0.00000371 0.00003787 0.00002322 0.9943652  0.00003114
  0.00021515 0.00265931 0.00010596 0.00255771]
 [0.00014284 0.00000316 0.00088069 0.00001164 0.00067388 0.00028095
  0.9976901  0.00000022 0.00027996 0.00003657]
 [0.0000005  0.9998481  0.00001408 0.00005343 0.0000008  0.00000454
  0.00001622 0.00000091 0.00005541 0.00000593]
 [0.00023124 0.00704155 0.00350841 0.01709301 0.00000095 0.9699637
  0.00002507 0.00001335 0.00137216 0.00075052]
 [0.00000479 0.9990164  0.00011481 0.00000937 0.00009504 0.00000502
  0.00001609 0.00000499 0.0007289  0.00000461]
 [0.00000166 0.00000828 0.00018815 0.00073716 0.00172293 0.00000747
  0.00000063 0.9669644  0.00002725 0.03034216]
 [0.00000044 0.00000447 0.00002037 0.00016557 0.98469293 0.00012634
  0.00004816 0.00041926 0.00069912 0.0138233 ]
 [0.00014292 0.00000093 0.00007995 0.00000516 0.00020675 0.00001203
  0.9995346  0.00000024 0.0000169  0.00000047]
 [0.00506382 0.00000374 0.0002552  0.00027891 0.07903916 0.00018168
  0.00010331 0.00096852 0.00023008 0.91387564]
 [0.00000009 0.00000007 0.00001448 0.00000002 0.00007941 0.00003181
  0.99984396 0.00000001 0.00003016 0.00000002]
 [0.00000603 0.00112843 0.00001682 0.00072586 0.00090505 0.00011647
  0.00000037 0.01774519 0.00015491 0.97920084]
 [0.00026336 0.00001345 0.00001828 0.00014518 0.9758664  0.00030628
  0.00014845 0.00020289 0.00130243 0.02173321]
 [0.00001244 0.00000003 0.00008187 0.00000037 0.00033492 0.00000552
  0.99943477 0.00000001 0.00012991 0.00000029]
 [0.00002768 0.00000016 0.0000075  0.00003329 0.0000035  0.00004393
  0.00005855 0.00000002 0.99981755 0.00000786]
 [0.00001368 0.00030855 0.996968   0.00224247 0.00000003 0.00000032
  0.0000009  0.00000041 0.00046545 0.00000034]
 [0.99287087 0.00001999 0.00041392 0.00026206 0.00008483 0.00311078
  0.0000349  0.00118449 0.00009018 0.00192798]
 [0.00001255 0.00001728 0.00094703 0.01166332 0.0037362  0.00011856
  0.00008581 0.00003245 0.93257076 0.05081612]
 [0.00001244 0.00000107 0.00002597 0.1349599  0.00000007 0.86472213
  0.00000001 0.00010447 0.00011649 0.00005752]
 [0.997045   0.00000375 0.00009739 0.00059744 0.00002181 0.00047617
  0.00051483 0.00082663 0.00001866 0.00039836]
 [0.00018604 0.9602836  0.00670487 0.0009231  0.00158843 0.00006977
  0.00001744 0.02373268 0.00610436 0.00038978]
 [0.00074644 0.00106728 0.01006396 0.98194134 0.00000471 0.00072449
  0.00000048 0.00276331 0.00000835 0.00267966]
 [0.00000097 0.00000132 0.00055702 0.00040382 0.00000239 0.0000008
  0.00000004 0.9989436  0.00000032 0.00008967]] (8.981 sec)
INFO:tensorflow:loss = 0.04535694, step = 19901 (18.053 sec)
INFO:tensorflow:probabilities = [[0.00000765 0.00067763 0.00007031 0.00040211 0.01317788 0.00004157
  0.00000592 0.01095119 0.00060731 0.97405845]
 [0.00000533 0.9992742  0.00006122 0.00003042 0.00002927 0.00003111
  0.00026377 0.00005784 0.00024286 0.00000393]
 [0.00000044 0.0000018  0.00010396 0.9994825  0.00000021 0.00004319
  0.         0.0000007  0.00022163 0.00014566]
 [0.00002097 0.000012   0.99297017 0.00614475 0.00002764 0.00001103
  0.00013934 0.00026579 0.00039033 0.00001801]
 [0.00011129 0.989019   0.00076224 0.00272806 0.00105737 0.00086151
  0.00037754 0.00024047 0.00422185 0.00062057]
 [0.00000065 0.         0.00002037 0.00003024 0.00000001 0.00000003
  0.         0.9999064  0.00000004 0.00004236]
 [0.9994179  0.00000071 0.00009872 0.00004887 0.00000062 0.00021747
  0.00000551 0.00002415 0.00018135 0.00000475]
 [0.00008241 0.00001682 0.00156234 0.00078995 0.00001836 0.000049
  0.00000176 0.00000303 0.9971123  0.00036412]
 [0.00002495 0.00005561 0.0000799  0.00001841 0.0000452  0.00016285
  0.99928826 0.         0.00032489 0.00000005]
 [0.00000597 0.9979685  0.00078217 0.00043085 0.00002839 0.00002614
  0.00002161 0.00009225 0.00053387 0.00011002]
 [0.00000367 0.00035277 0.10645187 0.00280509 0.0000003  0.00000458
  0.         0.88897103 0.00011655 0.00129413]
 [0.00000172 0.00000823 0.00007013 0.00051655 0.9400513  0.0001431
  0.00249006 0.00090225 0.00006812 0.05574859]
 [0.00000433 0.00000174 0.00122404 0.00000233 0.04060846 0.0000106
  0.9574813  0.00004264 0.00061118 0.00001321]
 [0.0003401  0.00009249 0.0012382  0.02733056 0.00000543 0.95210224
  0.00323144 0.00000008 0.0155574  0.00010199]
 [0.00015733 0.00005015 0.8944204  0.00071527 0.00037583 0.00005218
  0.00020808 0.09680494 0.00012465 0.00709118]
 [0.00197778 0.8748807  0.00033516 0.00014032 0.02708189 0.00000526
  0.00036825 0.05774886 0.0045981  0.03286362]
 [0.00000591 0.00010979 0.00021057 0.00008529 0.9939388  0.00016252
  0.00044275 0.000149   0.00159601 0.00329916]
 [0.00002208 0.00012365 0.00477796 0.94813013 0.00000792 0.00010875
  0.00002013 0.00000018 0.04680468 0.0000045 ]
 [0.00131732 0.04515383 0.00116664 0.9081464  0.00000041 0.04196856
  0.00000458 0.00058823 0.00002821 0.00162572]
 [0.00595316 0.0137182  0.00584991 0.00160463 0.02517628 0.71712446
  0.08162494 0.00140687 0.14662682 0.00091468]
 [0.00029991 0.04398823 0.0053368  0.84451973 0.0070242  0.00857224
  0.00021612 0.02161558 0.01525382 0.0531734 ]
 [0.00000781 0.00000009 0.00000053 0.00132195 0.00000167 0.99825054
  0.0000018  0.0000029  0.00038045 0.00003228]
 [0.00003107 0.00000147 0.00055555 0.00038858 0.00001752 0.00001647
  0.         0.9821292  0.00001128 0.01684892]
 [0.99910694 0.00000001 0.00007307 0.00000122 0.00000001 0.00081686
  0.00000086 0.00000029 0.00000048 0.00000047]
 [0.00000091 0.00000003 0.00005471 0.00000006 0.99974614 0.00000408
  0.00018169 0.00000028 0.0000001  0.00001199]
 [0.00007509 0.00001418 0.03682373 0.18470249 0.04496605 0.54248315
  0.0001893  0.00001995 0.01875614 0.17196989]
 [0.00000917 0.00000002 0.00000037 0.00000855 0.0000156  0.00005502
  0.0000012  0.00000018 0.9997732  0.0001367 ]
 [0.00085544 0.00000355 0.00133437 0.00000106 0.00061557 0.00026336
  0.99631304 0.00000003 0.0006116  0.00000203]
 [0.00010441 0.00000245 0.00028707 0.9823591  0.00063153 0.00483956
  0.00000156 0.00588803 0.00010499 0.00578127]
 [0.00000094 0.00000189 0.00001181 0.0000579  0.00000037 0.9993254
  0.00000458 0.00000036 0.00058479 0.00001202]
 [0.99987113 0.00000001 0.00002733 0.00003363 0.00000013 0.0000167
  0.00004905 0.0000012  0.00000073 0.00000017]
 [0.00007904 0.98263794 0.00292514 0.00154231 0.00008669 0.00449918
  0.00019083 0.00095322 0.00671409 0.00037168]
 [0.00000358 0.00000833 0.00000174 0.00000148 0.998439   0.00001556
  0.00001685 0.00001526 0.0000169  0.00148123]
 [0.9999974  0.         0.00000003 0.         0.         0.00000122
  0.00000101 0.00000048 0.         0.00000001]
 [0.00010104 0.00001749 0.00003032 0.00540673 0.00121681 0.97631675
  0.00001153 0.00497118 0.00175706 0.01017107]
 [0.00000163 0.00000066 0.00000405 0.0000001  0.00013463 0.00000955
  0.9998252  0.00000002 0.00002394 0.00000027]
 [0.00000553 0.00001097 0.00014288 0.00005206 0.00000635 0.0000063
  0.00000525 0.00000027 0.9997619  0.00000847]
 [0.00000168 0.00002246 0.0008422  0.99724185 0.00000001 0.00008269
  0.         0.00000372 0.00167254 0.00013284]
 [0.00000001 0.00000281 0.0000065  0.9998281  0.         0.00003752
  0.         0.00000004 0.00012315 0.00000187]
 [0.00002292 0.00000005 0.00000149 0.00011341 0.00154378 0.00002828
  0.00000041 0.00147488 0.00012117 0.9966936 ]
 [0.00032382 0.0000056  0.00028013 0.00001168 0.00045901 0.00007297
  0.9972812  0.00001002 0.00153268 0.00002297]
 [0.00000035 0.00000007 0.00000162 0.00000173 0.99859995 0.00010138
  0.00000153 0.00000226 0.00004545 0.00124548]
 [0.0000043  0.99859124 0.00009122 0.00012444 0.00000423 0.00000595
  0.00000155 0.00027186 0.00086075 0.00004442]
 [0.0000008  0.         0.00000602 0.00000254 0.98260087 0.00000099
  0.00001395 0.00006998 0.00000412 0.01730081]
 [0.00015841 0.02213568 0.00101651 0.96367216 0.00008766 0.00264988
  0.0000069  0.00067794 0.00238675 0.00720822]
 [0.9997781  0.00000001 0.0000446  0.00000025 0.00000231 0.00001734
  0.00012549 0.00000011 0.00000083 0.00003112]
 [0.00000332 0.00000002 0.00004494 0.00001438 0.98845786 0.00000402
  0.0000124  0.00011027 0.00003066 0.01132219]
 [0.00000234 0.00113512 0.07932988 0.13101494 0.00000008 0.6143933
  0.0005543  0.00000001 0.17356916 0.00000099]
 [0.00003336 0.00000039 0.00001007 0.00000052 0.9963767  0.00000237
  0.00009443 0.00038928 0.00066243 0.00243051]
 [0.00021275 0.9957705  0.00014986 0.00028588 0.00008208 0.00009898
  0.00003857 0.00089474 0.00192227 0.0005444 ]
 [0.00003547 0.00000106 0.00001823 0.00000053 0.00024886 0.00040601
  0.99928623 0.         0.00000361 0.00000016]
 [0.00121136 0.00004647 0.00005994 0.00000618 0.00005021 0.00043091
  0.9981932  0.00000008 0.0000013  0.00000039]
 [0.00040368 0.00002903 0.00087934 0.00028287 0.0002688  0.00315699
  0.00005382 0.00034636 0.9905872  0.00399197]
 [0.00002782 0.00014833 0.00023138 0.9931706  0.0000076  0.00187144
  0.00000238 0.00004292 0.00144521 0.00305227]
 [0.00002312 0.9992378  0.00004838 0.00002856 0.00010442 0.00001572
  0.00005922 0.00021774 0.00020892 0.00005611]
 [0.993357   0.00000001 0.00027187 0.00000625 0.00010446 0.00000299
  0.00621115 0.00000787 0.0000006  0.0000379 ]
 [0.00000726 0.00000009 0.00013408 0.00000011 0.0001686  0.00000925
  0.9996798  0.00000001 0.00000045 0.00000037]
 [0.00003066 0.00005972 0.0000114  0.01888036 0.00002667 0.97933084
  0.00029926 0.00000565 0.00004892 0.00130659]
 [0.00018428 0.00002081 0.00010356 0.0066663  0.00013586 0.9777875
  0.00147359 0.00000218 0.01347271 0.0001532 ]
 [0.00000192 0.0000013  0.00000418 0.00000207 0.00000021 0.9998301
  0.0000019  0.00000049 0.00015727 0.00000043]
 [0.00074939 0.0000003  0.00000678 0.00001296 0.00004357 0.00006137
  0.00000001 0.98712677 0.00000906 0.01198993]
 [0.00000043 0.01042569 0.9872384  0.00041282 0.0000001  0.00000075
  0.00000031 0.00000178 0.00191759 0.00000212]
 [0.00000262 0.00000039 0.02462034 0.5368669  0.00000003 0.00000228
  0.         0.43811658 0.00000098 0.00038979]
 [0.03483966 0.00002578 0.11238001 0.000074   0.00671062 0.00139438
  0.38273335 0.0000048  0.4618332  0.00000433]
 [0.00000004 0.00000137 0.00460128 0.99093586 0.         0.00001995
  0.         0.00000267 0.0044384  0.00000031]
 [0.00000254 0.00000061 0.00242577 0.0006661  0.         0.00000035
  0.         0.9969013  0.00000038 0.00000295]
 [0.00000133 0.9992716  0.00002515 0.00001203 0.00000121 0.00000016
  0.00001171 0.00001502 0.00065874 0.00000319]
 [0.00002087 0.00000214 0.00007729 0.00028717 0.9726061  0.00823937
  0.00004383 0.00112739 0.00087601 0.01671973]
 [0.00000043 0.00000002 0.9998591  0.00013925 0.00000038 0.00000006
  0.00000069 0.00000005 0.00000001 0.00000017]
 [0.00000001 0.         0.00000422 0.00000209 0.         0.
  0.         0.9999865  0.00000007 0.00000708]
 [0.00000022 0.00000061 0.00000425 0.00000164 0.00004083 0.00004235
  0.00000341 0.00000142 0.99988747 0.00001781]
 [0.00000252 0.00000212 0.00002056 0.0000012  0.00005789 0.00007668
  0.9998011  0.         0.00003778 0.00000014]
 [0.00072786 0.00120082 0.6797827  0.06275574 0.09106217 0.1104039
  0.01714718 0.02902685 0.00604745 0.00184546]
 [0.00071485 0.00000001 0.00004097 0.00000001 0.00379103 0.0000021
  0.9954464  0.00000022 0.00000013 0.00000424]
 [0.00004907 0.9955057  0.0005604  0.00041673 0.00003165 0.00005329
  0.00005948 0.00005813 0.00324093 0.00002456]
 [0.00002813 0.99918276 0.00005221 0.0000005  0.00000483 0.00000234
  0.00007035 0.00000983 0.00064645 0.00000255]
 [0.000003   0.997521   0.0004457  0.00020699 0.00019393 0.00003425
  0.00002084 0.0002539  0.00124065 0.00007978]
 [0.00004878 0.00003413 0.00062794 0.00004293 0.9886339  0.00000506
  0.0001055  0.00257614 0.00034519 0.00758034]
 [0.00001792 0.00000472 0.00003219 0.00000187 0.00003978 0.00057183
  0.99928707 0.         0.00004443 0.00000027]
 [0.00000125 0.00003165 0.00000308 0.00219989 0.0036528  0.00007417
  0.00000012 0.02560334 0.00000853 0.96842515]
 [0.00000151 0.         0.00000356 0.00001687 0.00000003 0.00000131
  0.         0.9999163  0.00000029 0.00006016]
 [0.00000002 0.         0.000001   0.00000074 0.98542887 0.00001032
  0.00000077 0.00000103 0.00000249 0.01455474]
 [0.0000183  0.00000004 0.00000101 0.00013528 0.00000124 0.00000578
  0.         0.99795085 0.00003899 0.00184848]
 [0.00002845 0.99745816 0.0000638  0.00012382 0.00003047 0.00007108
  0.00002891 0.00172485 0.00045335 0.00001715]
 [0.00000008 0.00000035 0.00000105 0.00004622 0.00000358 0.00000512
  0.         0.9996364  0.00003247 0.00027485]
 [0.00093047 0.09786985 0.7951297  0.09699854 0.00003969 0.00151935
  0.00046356 0.00681029 0.00023492 0.00000369]
 [0.99895275 0.         0.00001593 0.00000242 0.00000014 0.00048164
  0.00035638 0.00000006 0.00019008 0.00000057]
 [0.00255973 0.9094324  0.00114993 0.03347721 0.00008422 0.04525073
  0.00041848 0.00013919 0.00624587 0.0012422 ]
 [0.9996408  0.         0.00001966 0.00000178 0.00000027 0.00000602
  0.00000133 0.00001847 0.00000088 0.00031077]
 [0.00000305 0.9993556  0.00002739 0.00003849 0.00012585 0.00000177
  0.00002115 0.00010264 0.0002636  0.00006026]
 [0.00014307 0.00035147 0.98837984 0.00527873 0.00002704 0.00029058
  0.00000469 0.00373171 0.00019453 0.00159843]
 [0.00000202 0.         0.00000328 0.0000715  0.00000042 0.00000597
  0.         0.9997272  0.00000474 0.00018485]
 [0.00002246 0.00005    0.00151723 0.0000241  0.00234136 0.00017436
  0.9943045  0.00000022 0.00155996 0.00000582]
 [0.00000012 0.00000003 0.0000002  0.00003385 0.0000003  0.00000137
  0.         0.9998435  0.00000127 0.00011927]
 [0.000003   0.9981993  0.00008142 0.00022582 0.00031818 0.000451
  0.00009959 0.00006639 0.00039843 0.00015693]
 [0.0000114  0.00005037 0.00006644 0.00906421 0.00024701 0.00264311
  0.0000002  0.04855821 0.00026124 0.9390978 ]
 [0.00005282 0.00000591 0.00000293 0.00020119 0.00099735 0.00010624
  0.00000003 0.00456846 0.00023326 0.99383175]
 [0.00006175 0.00003516 0.00007575 0.97362894 0.0000009  0.02582441
  0.00001257 0.00000038 0.00030479 0.00005538]
 [0.00007681 0.00000012 0.00001763 0.00044845 0.00311233 0.00012406
  0.00000134 0.00742898 0.00025018 0.9885401 ]
 [0.00001004 0.00000367 0.00015505 0.00000412 0.00121933 0.00004468
  0.9985536  0.00000004 0.00000902 0.00000052]] (9.299 sec)
INFO:tensorflow:Saving checkpoints for 20000 into /tmp/mnist_convnet_model\model.ckpt.
INFO:tensorflow:Loss for final step: 0.1431061.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2018-11-15-23:11:28
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\model.ckpt-20000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Finished evaluation at 2018-11-15-23:11:34
INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9698, global_step = 20000, loss = 0.10296154
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /tmp/mnist_convnet_model\model.ckpt-20000
{'accuracy': 0.9698, 'loss': 0.10296154, 'global_step': 20000}
Press any key to continue . . .
"""